---
title: "9:38:21 AM - June 16, 2025"
date: 2025-06-16T16:38:21.942Z
timestamp: 1750091901942
---

## Project Notes

## Anthropic SDK Streaming Research Complete

### Current Setup
- **Version**: @anthropic-ai/sdk@^0.30.1 (older version, latest is 0.54.0)
- **Current Implementation**: Non-streaming `this._anthropic.messages.create(requestPayload)`
- **Architecture**: Already has streaming infrastructure with `agent_token` events and 'streaming' state

### Streaming API Patterns Found

#### 1. Using `messages.stream()` (Recommended)
```typescript
const stream = client.messages.stream({
  messages: [{ role: 'user', content: 'Hello' }],
  model: 'claude-3-5-sonnet-latest',
  max_tokens: 1024,
});

// Event-based approach
stream.on('text', (text) => {
  console.log(text); // Incremental text chunks
});

stream.on('contentBlock', (content) => {
  // Full content block when complete
});

stream.on('message', (message) => {
  // Final complete message
});

// Async iteration approach
for await (const event of stream) {
  console.log('event', event);
}

// Get final result
const finalMessage = await stream.finalMessage();
```

#### 2. Using `messages.create()` with stream: true
```typescript
const stream = client.messages.create({
  ...,
  stream: true
});

// Returns async iterable of events only
for await (const event of stream) {
  // Process events
}
```

### Event Types
- `text`: Incremental text content
- `contentBlock`: Complete content block
- `message`: Final complete message
- `content_block_delta`: Contains `{type: "text_delta", text: "..."}`

### Implementation Strategy
1. **Backward Compatibility**: Keep existing non-streaming method
2. **New Streaming Method**: Add `createStreamingResponse()` method
3. **Agent Integration**: Use existing `agent_token` events
4. **State Management**: Use existing 'streaming' AgentState

### Key Differences from LMStudio
- LMStudio: Simple async iterable with `{content?: string}` chunks
- Anthropic: Rich event system with multiple event types and structured data
